services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: stackoverflow-rag-api
    ports:
      - "5000:8080"
    env_file:
      - .env  # Load environment variables from .env file (gitignored)
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      # OpenAI Configuration (.NET format)
      - OpenAI__ApiKey=${OpenAI__ApiKey}
      - OpenAI__EmbeddingModel=${OpenAI__EmbeddingModel:-text-embedding-3-small}
      - OpenAI__ChatModel=${OpenAI__ChatModel:-gpt-4o-mini}
      # Qdrant Configuration (container network - use service name)
      - Qdrant__Host=http://qdrant:6333
      - Qdrant__CollectionName=${Qdrant__CollectionName:-stackoverflow_chunks}
      # Ingestion Configuration
      - Ingestion__CsvPath=/data/stacksample.csv
      - Ingestion__MaxRows=${Ingestion__MaxRows:-10000}
      - Ingestion__ChunkSize=${Ingestion__ChunkSize:-500}
      - Ingestion__ChunkOverlap=${Ingestion__ChunkOverlap:-50}
    volumes:
      - ./data:/data:ro
    depends_on:
      - qdrant
      - redis
    networks:
      - stackoverflow-rag
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: stackoverflow-rag-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    networks:
      - stackoverflow-rag
    restart: unless-stopped

  redis:
    image: redis:7.2-alpine
    container_name: stackoverflow-rag-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - stackoverflow-rag
    restart: unless-stopped
    command: redis-server --save 60 1 --loglevel warning

volumes:
  qdrant_storage:
    driver: local
  redis_data:
    driver: local

networks:
  stackoverflow-rag:
    driver: bridge
